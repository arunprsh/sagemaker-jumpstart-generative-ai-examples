{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15961f18-d3a9-487a-bdcb-8262a3559aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Form Text Summarization using JumpStart Foundation Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878b09a-a77a-4e45-bed9-c5d86c92b6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install cohere_sagemaker\n",
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a91625-57ea-4b19-be66-58a0155492d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part - I: Hosting the foundation model for real-time inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd748ea5-ae04-4d85-8a6e-fe6632b7ecd5",
   "metadata": {},
   "source": [
    "#### I. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14875767-3da4-4c00-8ea9-fa62a3c3ed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from cohere_sagemaker import CohereError\n",
    "from cohere_sagemaker import Client\n",
    "from sagemaker import ModelPackage\n",
    "import cohere_sagemaker\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d35c85-fac3-4fa6-877a-2246fba8f721",
   "metadata": {},
   "source": [
    "#### Setup Logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e14df3-fca6-4bdb-8a08-38d7317e2510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268eb12-e655-447b-97dd-7a58259823d2",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e312761d-7a08-4038-94a8-03034092031d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using SageMaker version: 2.132.0]\n",
      "[Using Boto3 version: 1.26.69]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')\n",
    "logger.info(f'[Using Boto3 version: {boto3.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da9b21-2e08-418f-8c4b-42b2a33ddf61",
   "metadata": {},
   "source": [
    "#### II. Setup essentials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc66e6-5320-4cf0-97bc-3431c1fe3119",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0003673-c89d-451d-9e64-a7cbdb12ff79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    'us-east-1': 'arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421',\n",
    "    'eu-west-1': 'arn:aws:sagemaker:eu-west-1:985815980388:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc6314-af70-4c0e-948b-07281f92fadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "logger.info(f'Region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2390933-932e-40fa-9a43-184732af08bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f'Unsupported region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda2dc1-8d66-469d-a55a-88800189aa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_ARN = model_package_map[region]\n",
    "logger.info(f'Model package ARN = {MODEL_PACKAGE_ARN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4e24-3a4f-48c7-b101-d5beebc671f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROLE = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "logger.info(f'Role = {ROLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058120d-959c-438d-84dd-654a4a59b281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "MODEL_NAME = f'cohere-medium-{timestamp}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df073add-7a6c-4cc2-9f18-f1ac530656c6",
   "metadata": {},
   "source": [
    "#### III. Create a SageMaker endpoint for real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc86f6-80cd-4a69-9cc8-d1a6d8eec9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ModelPackage(role=ROLE, \n",
    "                     model_package_arn=MODEL_PACKAGE_ARN, \n",
    "                     sagemaker_session=session, \n",
    "                     name=MODEL_NAME)\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66dc5c-566b-4676-bdbb-88859b5588a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_INSTANCES = 1\n",
    "INSTANCE_TYPE = 'ml.g5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c65cd-2b70-4f3d-8ab9-05d24f47a4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.deploy(NUM_INSTANCES, \n",
    "             INSTANCE_TYPE, \n",
    "             endpoint_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a49ff-04e0-4955-bf38-bf5188c5445d",
   "metadata": {},
   "source": [
    "## Part 2: Long-form abstractive text summarization of legal judgement docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea909b2-32d1-496c-b9f2-ff64687d21d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### I. Read, parse and chunk docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0292a2c-f748-4a70-bbb5-99abb1c3d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name = '5.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398c16c4-227e-453d-b1de-a797e9df3745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_lines = []\n",
    "with open(f'./docs/{doc_name}', encoding='iso-8859-1') as doc:\n",
    "    for line in doc.readlines():\n",
    "        line = line.strip()\n",
    "        line = re.sub(' +', ' ', line)\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.replace('\\t', '')\n",
    "        line = line.replace('  ', ' ')\n",
    "        if len(line) > 0:\n",
    "            cleaned_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e04bf171-b616-40ef-88a5-3af6684ca010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4168"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = ' '.join(cleaned_lines)\n",
    "doc = doc.split()\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97c3297f-b741-41c8-b051-2932dc480306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 768\n",
    "chunks = [' '.join(doc[i:i+chunk_size]) for i in range(0, len(doc), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1bd4c8b-71cc-46ef-a666-361ccb1f49b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e178c9-371f-4320-8675-94676147af97",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### II. Short-form Abstractive Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad86bc79-1df9-45af-aa66-4073b8269f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'cohere-medium-1679931302'\n",
    "# ENDPOINT_NAME = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c683d6bb-196d-4779-bd3e-c5cc92556988",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "398cefc4-9fe3-4b4e-ad7d-acbe5dcafc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_by_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f9272c2c-9b82-4958-982b-fc692ac5b2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:43<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 11.5 ms, total: 50.5 ms\n",
      "Wall time: 43.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "    prompt = f'Context = {chunk}\\nSummarize the above context.'\n",
    "    response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.2, \n",
    "                           return_likelihoods='GENERATION')\n",
    "    generated_text = response.generations[0].text\n",
    "    summaries_by_chunks.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "84046d3c-3621-4cee-836b-dc0d29ae5e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_summaries = []\n",
    "STOP_SEQ = '. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e934d7bb-56a9-46cf-8e79-546dbe4c5ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_summary(summary):\n",
    "    valid_sents = []\n",
    "    sents = summary.split(STOP_SEQ)\n",
    "    last_sent = sents[-1]\n",
    "    if not last_sent.endswith('.'):\n",
    "        sents = sents[0:-2]\n",
    "    return ' '.join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6403ef8-e20c-450e-8833-efc26c76b4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for summary in summaries_by_chunks:\n",
    "    summary = summary.replace('\\n', '')\n",
    "    summary = summary.replace('  ', ' ')\n",
    "    summary = summary.replace('\\'', '')\n",
    "    summary = summary.strip()\n",
    "    cleaned_summary = clean_summary(summary)\n",
    "    if not cleaned_summary.endswith('.'):\n",
    "        cleaned_summary = cleaned_summary + '.'\n",
    "    if len(cleaned_summary) >= 64:  # atleast 64 chars\n",
    "        cleaned_summaries.append(cleaned_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2937605-d14b-47d8-897b-6e00e5def613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total number of short summaries generated = 6\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Total number of short summaries generated = {len(cleaned_summaries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced2a16-6104-48ec-b224-6bb772f03329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### III. Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0166b9f9-f74e-41d2-843e-9ad947e0f0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_map = {}\n",
    "total_questions_generated = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24f4ddd9-1ae3-4f44-b338-e1a48affd4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detect_words = ['why', 'how', 'what', 'who', 'where', 'is', 'when', 'which', 'whose', 'are', 'do', 'does', 'can', 'could', 'should', 'will', 'have', 'has']\n",
    "\n",
    "def is_a_question(question):\n",
    "    first_word = question.split()[0]\n",
    "    if first_word.lower() in detect_words:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb4ddcaf-9855-424c-9ce1-ad0e808329d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:22<00:00, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 ms, sys: 5.12 ms, total: 38.8 ms\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for summary in tqdm(cleaned_summaries):\n",
    "        prompt = f\"\"\"EXTRACT QUESTIONS\n",
    "        Context: \n",
    "        {summary}\n",
    "        Questions:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                                   max_tokens=512, \n",
    "                                   temperature=0, \n",
    "                                   return_likelihoods='GENERATION')\n",
    "            generated_text = response.generations[0].text\n",
    "            questions = generated_text.split('\\n')\n",
    "            cleaned_questions = set()\n",
    "            for question in questions:\n",
    "                if len(question) > 5:\n",
    "                    question = re.sub(r'\\d+\\.', '', question)\n",
    "                    question = question.replace('Q:', '')\n",
    "                    question = question.strip()\n",
    "                    if is_a_question(question) is True:\n",
    "                        cleaned_questions.add(question)\n",
    "            total_questions_generated += len(cleaned_questions)\n",
    "            questions_map[summary] = cleaned_questions\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "370ccdb9-4004-4865-b095-71840b7ce90a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total questions generated = 28\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Total questions generated = {total_questions_generated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726a133-93b9-4a77-a296-d77f3da4dea0",
   "metadata": {},
   "source": [
    "#### 4. Abstractive Question & Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40e49f01-d549-4d1c-a527-56a1ced04b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:36<00:00, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.5 ms, sys: 10.1 ms, total: 88.7 ms\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for context, questions in tqdm(questions_map.items()):\n",
    "    for question in questions:\n",
    "        prompt = f\"\"\"Context = {context}\n",
    "        Question = {question}\n",
    "        Answer = \n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.generate(prompt=prompt, \n",
    "                               max_tokens=128, \n",
    "                               temperature=0, \n",
    "                               return_likelihoods='GENERATION')\n",
    "\n",
    "            generated_text = response.generations[0].text\n",
    "            answer = generated_text.strip()\n",
    "            qa_pairs.append((doc_name, context, question, answer))\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2ed3e-b255-4ff3-9141-bcae17413612",
   "metadata": {},
   "source": [
    "#### 5. Combine short summaries into a long form summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "951e0770-dcf6-445a-b1db-ccf6b3c16692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_form_summary = []\n",
    "for short_summary in cleaned_summaries:\n",
    "    short_summary = short_summary.replace('\\'', '')\n",
    "    long_form_summary.append(short_summary)\n",
    "long_form_summary = '\\n\\n'.join(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8681ce1-957b-4d06-a19e-f17655d689d5",
   "metadata": {},
   "source": [
    "#### 6. Write long form summary and QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3175b0f3-b6c3-43a6-b918-c53052eb452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./summaries/summary_5.txt', 'w') as out:\n",
    "    out.write(long_form_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f649fe-4eff-4fc9-af77-5a144b9d2fb6",
   "metadata": {},
   "source": [
    "#### 7. Write QA pairs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "60eb9d45-9649-4c91-896c-22c416a21615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>short_summary</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the position of the plaintiffs?</td>\n",
       "      <td>The plaintiffs are entitled to the reversion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the effect of the first question?</td>\n",
       "      <td>The first question is about the nature of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the effect of the award?</td>\n",
       "      <td>The effect of the award is that the plaintiffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the nature of the award?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>The context is a civil appeal filed by Bakshi ...</td>\n",
       "      <td>What is the position of the defendants?</td>\n",
       "      <td>The defendants say that it gave Mst. Mohan Dei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_name                                      short_summary  \\\n",
       "0    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "1    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "2    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "3    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "4    5.txt  The context is a civil appeal filed by Bakshi ...   \n",
       "\n",
       "                                    question  \\\n",
       "0    What is the position of the plaintiffs?   \n",
       "1  What is the effect of the first question?   \n",
       "2           What is the effect of the award?   \n",
       "3           What is the nature of the award?   \n",
       "4    What is the position of the defendants?   \n",
       "\n",
       "                                              answer  \n",
       "0      The plaintiffs are entitled to the reversion.  \n",
       "1  The first question is about the nature of the ...  \n",
       "2  The effect of the award is that the plaintiffs...  \n",
       "3                                                     \n",
       "4  The defendants say that it gave Mst. Mohan Dei...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(qa_pairs, columns=['doc_name', 'short_summary', 'question', 'answer'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "085a52a8-ef54-43aa-af1b-f0a3385c8a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./qa_pairs/qa_pairs_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f965d-7f58-45ed-80e7-cd93b82e9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
